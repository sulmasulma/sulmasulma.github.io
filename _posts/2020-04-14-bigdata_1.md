---
layout: post
title: 빅데이터 시대의 데이터 관리
tags: [Big Data, Data Lake, Data Warehouse, Data Mart, Distributed Processing]
categories: [Data]
excerpt_separator: <!--more-->
---
빅데이터 시대에 자리잡은 데이터 관리 방법의 특징을 정리해 보았다.<!--more--> 빅데이터(big data)라는 단어는 2011년 후반에서 2012년에 걸쳐 많은 기업들이 데이터 처리에 분산 시스템을 도입하기 시작했을 무렵 등장했다. 대표적으로 등장하게 된 기술로 `Hadoop`과 `NoSQL`이 있다.

### Hadoop
- 다수의 컴퓨터(수백 대, 수천 대 단위)에서 대량의 데이터를 처리하기 위한 시스템
- 초기에는 구글에서 개발된 분산 처리 프레임워크인 `MapReduce`를 참고하여 제작됨. 이 경우 데이터 처리를 위해 `Java` 언어로 프로그래밍 해야 했기 때문에, 접근성이 좋지 않았음
- 이후 `SQL`과 같은 쿼리 언어를 Hadoop에서 실행하기 위해 `Hive`가 2009년에 출시
  - `Hadoop`을 이용한 분산 시스템의 사용자가 확대됨

### NoSQL
- 전통적인 RDB(Relational Database)의 제약을 제거하는 것을 목표로 한 데이터베이스의 총칭
- NoSQL의 종류
  1. key-value store (KVS)
    - 다수의 key-value를 관련지어 저장
    - `Riak`, `Redis`
  2. document store
    - json과 같은 복잡한 데이터 구조 저장
    - `MongoDB`, `CouchDB`
  3. wide-column store
    - 여러 key를 사용하여 높은 확장성을 가짐
    - `Cassandra`
- `NoSQL`에 데이터를 기록하고 `Hadoop`으로 분산 처리하는 흐름이 2012년부터 퍼지게 됨
- 2013년 이후에는 `Spark`와 같은 분산 처리 프레임워크의 등장으로 `MapReduce`보다 효율적으로 데이터 처리를 할 수 있게 됨

### 분산 시스템과 데이터 웨어하우스의 용도 구분
- 전통적인 데이터 웨어하우스의 경우 대량의 데이터를 처리할 수 있으며 `Hadoop`에 비해 성능상 우수한 점도 있음
- 다만 데이터 용량을 늘리려면 하드웨어를 교체하는 등 확장하기가 어려운 문제가 있었음
- 이에 따라 다음과 같이 구분
  - **지속적으로 늘어나는 데이터 처리**: `Hadoop`
  - **비교적 작거나 중요한 데이터 처리**: 데이터 웨어하우스
- 클라우드 서비스의 보급으로 인해, 물리적인 하드웨어를 통해 이러한 시스템을 구축하지 않아도 되게 되었음
  - 클라우드에서의 Hadoop: `Amazon Elastic MapReduce`, `Azure HDInsight`
  - 데이터 웨어하우스: `Google BigQuery`, `Amazon Redshift`
- 다만 분산 처리 시스템의 경우 [MapReduce 방식](https://12bme.tistory.com/154)을 사용하기 때문에 10만 개 이하 행 정도의 스몰 데이터에서는 오히려 속도가 느릴 수 있음
  ![메모-5](https://i.imgur.com/BGOnl7Z.jpg)

### 데이터 디스커버리
- 데이터 웨어하우스에 저장된 데이터를 시각화하려는 방법으로 등장
- `Tableau`와 같은 BI Tool을 사용하여 **대화형으로 데이터를 시각화하여 가치 있는 정보를 찾으려고 하는 프로세스** 를 말함

### 스트림 처리와 배치 처리
  - 파일 서버에 축적된 로그 파일, 모바일 앱에서 수집된 이벤트 데이터, 임베디드(embedded) 장비에서 전송된 센서 데이터 등 여러 소스/형태의 데이터를 수집하게 됨
  - 데이터 전송(data transfer) 방법은 크개 두 가지
    1. 벌크(bulk) 형
      - 이미 존재하는 데이터를 추출하는 방법
      - DB와 파일 서버 등에서 **정기적으로** 데이터를 수집하는 데에 사용
    2. 스트리밍(streaming) 형
      - 계속해서 생성되는 데이터를 끊임없이 전송하는 방법
      - 모바일 앱, 임베디드 장비 등에서 데이터를 수집하는 데 사용
  - 기존의 경우 데이터 웨어하우스에서 다루는 데이터는 주로 벌크형 방법이 사용되었으나, 모바일 앱이 증가함에 따라 **스트리밍형 방법** 이 주를 이루게 됨
    - 예를 들어, 실시간 음원 차트의 경우 최근 30분간 취합한 데이터를 집계하여 제공
  - 스트리밍형 처리는 장기적인 데이터 분석에는 적합하지 않음. 지난 1년 간의 데이터를 분석하려고 하면 수 천 배, 수만 배로 크기가 증가하기 때문
  - 장기적인 데이터 분석을 위해서는 어느 정도 정리된 데이터를 효율적으로 가공하기 위한 **배치 처리** 를 해야 함

### 데이터 웨어하우스와 데이터 마트, 그리고 데이터 레이크
- **데이터 웨어하우스**
  - 기본적으로 raw data를 장기 보존용으로 정리한 테이블 구조의 데이터를 말함
  - 일반적인 RDB와 달리 **대량의 데이터를 장기 보존** 하는 것에 최적화되어 있음. 정리된 데이터를 한 번에 전송하는 것은 뛰어나지만, 소량의 데이터를 자주 쓰고 읽는 데에는 적합하지 않음. 시스템의 과부하를 초래하게 됨
- **데이터 마트**
  - 데이터 분석과 같은 목적에 사용하는 경우, 데이터 웨어하우스에서 **필요한 데이터만을 추출** 한 것
  - BI Tool과 조합시켜 **데이터 시각화** 목적으로도 사용
  - raw data를 추출하고 필요하에 따라 가공하여 저장하는 일련의 과정을 **ETL 프로세스** 라고 함
    - E(Extract) - T(Transform) - L(Load)
- **데이터 레이크**
  - 빅데이터의 시대가 되면서 ETL 프로세스 자체가 복잡해지고, 모든 데이터가 데이터 웨어하우스를 가정해서 만들어지지 않음
  - 모든 데이터를 원래의 형태로 축적해 두고, 나중에 필요에 따라 가공함. 이 때 **데이터의 축적 장소** 를 데이터 레이크(data lake)라고 함
    - raw data를 저장하는 저장소라고 생각하면 됨
  - 단순한 스토리지이며, `MapReduce` 등의 분산 데이터 처리 기술을 이용하여 필요한 데이터로 가공함
