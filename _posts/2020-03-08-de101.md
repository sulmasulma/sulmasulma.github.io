---
layout: post
title: 데이터 엔지니어링 기초
tags: [Data Engineering, Data Lake, Data Warehouse, DL, DW]
author-id: matthew
excerpt_separator: <!--more-->
---
 데이터 엔지니어링 입문용 슬라이드인 강대명님의 [**데이터 엔지니어링 101**](https://www.slideshare.net/charsyam2/data-engineering-101) 자료를 정리해 보았습니다.<!--more-->

- Google Analytics는 웹 로그 수집 툴. 이와 비슷하게 PV(Page View), UV(Unique View) 등의 데이터(로그)를 수집하는 것을 예로 듦
- 데이터 엔지니어링 과정: **ETL**
  - Extract(Data Lake) - Transforma - Load(Data Warehouse)
- 데이터 파이프라인이 필요한 이유
   - UV, PV 같이 단순한 수치 몇개로 충분하다면, 데이터 파이프라인은 필요하지 않음. 훨씬 더 많은 수치가 필요할 경우 필요한 과정
   - 단순히 raw data에서 데이터 추출이 아니라, 여러 데이터들이 관계를 가지거나 중간 중간에 변환되어 추출해야 하는 경우에 사용
   - 데이터들 간의 의존성/단계성이 있으며, 중간에 에러가 발생함 → 워크플로우 관리 툴 필요!
       - `Pinball`, `Airflow`, `Luigi` 등
       - 작업마다 필요한 컴퓨팅 파워(메모리/cpu)가 다름
       - 특정 시간에 돌아야 하거나, 실패했을 때 관리해 줌

### ETL 과정
1. **Extract**: 데이터 수집
   - 로그 **수집**: `Logstash`, `fluentd`, `syslogd`
   - 로그 **저장**: `hdfs`, 성능 좋은 NAS, 클라우드 스토리지, `Kafka`, RDBMS
   - 수집하여 통계작업 하는 것까지의 과정(→ 분석 DB 말하는 건가?)
2. **Transform**: 데이터 처리
   - 많은 양의 데이터를 한 대에서 처리할 수 없음 → 분산처리
   - 대량의 데이터 정렬: Bucket sort 알고리즘
   - SQL 기반: `SparkSQL`, `Hive`, `Presto`, `Redshift`, `Bigquery`
   - 코드 기반: `Hadoop MapReduce`, `Spark`
3. **Load**: 데이터 저장
   - 처리한 데이터를 빠르게 serving하기 위한 저장소 필요
   - ETL 결과를 또다른 ETL의 입력으로 사용한다면?
