---
layout: post
title: 데이터야놀자 강의내용 메모
tags: [jupyter, jupyter-lab, chrome]
author-id: matthew
excerpt_separator: <!--more-->
---
<!--more-->

### 1. 데놀: Serverless에서 유저 컨텐츠 추천 서비스 in 빙글
- 추천 시스템의 정의? -> 좋아할 만한, 관심 있을 만한 아이템 자동 제공
- '읽지 않았던' 컨텐츠를 자동으로 제공해 주는 것. 컨텐츠 간의 유사도를 매겨야 함
  - Euclidean, jaccard, cosine similarity(여기서 많이 사용. 크기가 아닌 **각도** 사용)
- 유저 추천: user-based vs contents-based
  - user-based
    - 유저들이 좋아하는 항목(예: [1,1,0,0,1])들의 코사인 거리 계산
  - contents-based
    - 컨텐츠 특성들의 코사인 거리 계산

- 빙글의 Serverless Architecture
  - S3, 아테나 등: aws 항목들인가?
  - id별 similarity 데이터를 json 형태로 저장하여 SQL 쿼리만 날리면 가져올 수 있게 함

- 인스타그램 Tag 이용!
- K-means 클러스터링 문제: random centroid(centroid들이 너무 밀집될 가능성이 있음), unbalanced input(DBSCAN 써야하는 인풋 데이터)
  - K-means++: 너무 가깝게 centroid가 지정될 확률이 작아짐.
  - Spherical K-means: 거리 계산을 Euclidean 말고 cosine으로 바꿈 -> 거리가 아닌 각도를 계산하여 더 비슷한 것들을 추천할 수 있게 함

- 개발상 문제: 유저가 api call 할 때만 추천 시스템을 새롭게 생성해야 함. 불필요할 경우에도 추천하면 메모리 낭비
  - sql 쿼리는 상관 없는데, sklearn 갔다 오는게 오래 걸림. 이 과정을 최적화하여 소요 시간 줄임
  - python model(sklearn) 말고 Typescript로 직접 만듦 -> 유지보수를 계속 할 수 있게

- 추천 시스템: 검증이 어려움. 시스템을 만들었는데 유저 만족도가 좋지 않을 수 있음.
  - ex) input data가 적을 경우

- Q&A
  - 데이터가 많아질 경우 matrix 계산 등 어려운데, 어떻게 했는지?
    - 이전의 모든 컨텐츠를 가져온 것이 아니라, 날짜 등으로 필터링하여 조건에 맞는 데이터만 가져왔음. 데이터가 엄청 많은 heavy user도 별로 없었음
  - K-means의 K는 어떻게 정했는지?
    - 유저들에게 추천되는 컨텐츠 수를 보고 결정
  - Light user들은 input data가 적어 추천이 잘 되지 않음. 어떻게 해결했는지?
    - Guest(로그인 안한 유저)들이 본 컨텐츠 등 이용하여, 기존에 있었던 컨텐츠 보여줌(추천 시스템은 아님)

### 2. 나의 리터러시 != 너의 리터러시: 잘 전달하기 위해 데이터 시각화할 때 고려하는 것들
- 언론사 디자이너 관점에서 시각화 경험(인포그래픽 등) 공유
- 사용자 중심의 디자인(리터러시)
- 네이버 뉴스: 80% 이상 모바일로 접속
- 같은 데이터를 가지고 다양한 시각화 (사람마다 다르게)
  - DVL(Data visualization & Literacy) 연구 중
<br/>
- [KBS 디지털뉴스](news.kbs.co.kr): 데이터룸 있음. 취재기자, 개발자, 데이터분석가, 디자이너 등으로 구성
- 2019.10.17 기사: 프로야구 전력차 ~년만에 최대
  - 기사 원고와 데이터를 가지고 스케치(구단별 승률, 전력 분포도)
  - 카테고리별 산점도 보기, 연도별 구단 전력 표준편차 등 막대그래프로
    - 근데 산점도, 표준편차 이런 개념들도 설명하기 어려울 수 있음
  - 박스플롯 등 의미를 잘 모르면 전달 어려움
    - 대신 한 선에 야구공 위치 그린 그림 좋은 듯
- 분석가가 R로 시각화하는 경우: 거의 없음
  - R to illustrator 이용하기도 함
  - 데이터를 받아서 다시 시각화함
- 보통 스압 있는 건 잘 넣지 않지만, 모바일을 위해 되게 긴 그림을 넣어서 한국이 행복지수 최하위인 데이터는 스크롤 내리면서 체감할 수 있도록 하기도 함
- 모바일용, 데스크탑용 따로 제작
- 개발자가 사용하는 색, 디자이너가 사용하는 색이 다름
  - 색각이상자 고려. 총 인구의 3% 정도 되기 때문
  - 적록색맹이 가장 많기 때문에 적/록 배색은 잘 하지 않음
- 매직넘버 4: 작업 기억 한계 용량. 그래서 색상을 3~5개로 사용 제한하기도 함
  - 일반인에게 보이는 색 / 적록색맹에게 보이는 색 고려하여 색상 조합 선택
- 보통 ``원/꺾은선/막대``로 거의 표현하는데, 이러기 어려운 경우 다른 시도 하기도 함(정당 지지율 그래프인 듯)
- 스크랩 많이 하심. 토픽별, 목적별로 시각화가 다름
- 데이터 속성을 고려하여 모양, 문자, 방향, 여백 등 고려함 (일종의 시각화 번역 작업)
- 컬러 툴 활용. 포토샵, 구글 spectrum, 구글 colorpick ~, chroma.js 등
- 색상들의 느낌 고려


### 3. 한글 검색, 고민해야 할게 많아요
- [슬라이드](https://ela.st/denol-19)
- 대기업, 스타트업 등 일 하시다가 엘라스틱에 푹 빠져서 여기서 일하시는 중
- Elastic
  - 검색 엔진. 꼭 텍스트, 숫자를 치지 않더라도 모바일 앱에서 지도 앱에서 손가락 줌인, 줌아웃 하는 것도 검색 행위. 조건(좌표)에 맞는 데이터를 찾아주는 것
  - 윈도우 탐색기에서 파일 찾을 때 등 사용
  - 시계열 데이터를 가지고 로그 분석하는 기능도 있음. 전세계 배틀넷 서버도 분석
  - 검색엔진 1위, 전체 DB에선 7위
- ELK 스택 (엘크): Beats가 추가됨
- IT 기업의 딜레마: 회사 제품 등 홍보하는 건 발표가 잘 허용되지 않음. 다만 서비스 운영사 등에서 `Elastic을 이용하여` 발표하는 내용 등이 있음
- Elastic Stack을 이용한 지하철~~: 발표 데모 자료로 많이 쓰였음
- Kibana: 시각화 도구인가? 한 번 써보기
- 유튜브 `Elastic Stack 활용 데모` -> 봐 보기. 연습하는 데 좋음
<br>
- 오늘 발표 내용: 제작 과정 중에 한글 검색을 구현하면서 발생한 에피소드
  - 과거에는 한글 검색 전혀 고려하지 않았음. 역검색이 한글로 가능하도록 함
- 검색 엔진: 기본적으로 Full Text 검색이 가능해야 함
  - DB는 인덱스별 단어를 저장
    - 키워드가 늘어나면 데이터가 많아짐
  - ES는 단어들의 위치를 저장 -> 그래서 테이블의 형태가 다름
    - 키워드가 늘어나도 키워드의 수가 잘 많아지진 않음. 다만 인덱스의 개수가 많아질 뿐(예: 1,2p -> 1,2,5p)
  - 대소문자 편집, 관사 삭제, 영어는 s(복수형)를 원문으로 저장. jumps 검색해도 jump 나올 수 있도록
  - 동의어 검색도 가능하게 함. fast - quick
- 한글 검색은 좀 다름
  - 무작정 띄어쓰기로 구분하면 안 됨. 동해물과 백두산이: 동해+물 / 백두+산
- 한글 형태소 분석기: 은전아리랑, Nori 등
- 지하철 역 정보 데이터셋 + 다국어(한/일/영) 데이터셋
  - 역 code의 경우 모든 역에 있지 않았음. 역명은 데이터셋마다 다르기도 함.
  - Nori: 일반 텍스트(영어). standard analyzer
  - Nori-only:
- `홍대입구` 역
  - 스탠다드 애널라이저는 "홍대입구"로만 저장. 홍대로 검색하면 안 나옴
  - nori_only: 필드 만들어 입력 텍스트, 저장되는 텍스트가 모두 한글 형태소 분석기 통해 처리
  - 이러면 홍대+입구 분리되어 '입구'에 해당하는 역도 모두 나옴. 서울대입구 등
  - 관련된 최대한 많은 결과 보여줄 건지(쇼핑몰 추천), 가장 정확한 거만 보여줄 건지는 서비스의 형태에 따라 결정
  - station.name.nori 필드
    - 저장은 홍대, 입구, 홍대입구 모두 저장
    - shingle 토큰 필터로 가공 처리: Ngram 토큰 필터와 비슷함.
      - Ngram: house가 있으면 h, ho, hou, hous 모두 저장
        - 원문이 짧아도 저장 용량이 매우 많음
        - 다만 세세한 검색 필요한 경우(알파벳 하나만 쳐도 나올 수 있게) 좋음. 자동완성 기능 사용시
      - Shingle: this is my sweet home 있으면 this is, is my 등을 저장. 구문 검색시 유용
    - 검색은 스탠다드 애널라이저로 함. 그래서 홍대, 입구 등으로 검색해도 홍대입구가 나옴
  - 게스트 계정 데모 가능: ela.st/cloud-kr
  - ES: 쿼리도 json 형식으로 되어 있음. 위 사이트 들어가서 requests 보면 json 형태로 나옴
  - 텍스트 뿐만 아니라 위치 정보도 담고 있기 때문에, 우버나 가까운 호텔 찾기 등에도 사용
    - 우버 경우 같은 경로를 가더라도 실시간 정보에 따라 수요, 공급이 바뀌면서 가격이 바뀜
- 페이스북 그룹 elasticsearch.kr도 있음
- esbook.kimjimin.net: 책 정보. kimjimin.net: 블로그

### IGNITE: 식습관 스몰데이터 분석을 통한 장트러블 극복기
- 장 트러블에 영향 있는 음식군
- 쾌변에는 생활 습관, 운동 등 여러 영향 있지만 경험적인 근거를 통해 식사 데이터 수집
- 메뉴들의 맵기, 차가운 것, 커피 등
- 쾌변한 정도, 화장실 간 시간/횟수
- 설명변수: 알코올, 우유 등. 변수 backward 제거
- 그래서 앞으로 화장실에서 보낼 시간 예측

### 4. 카트라이더 TMI 포스트모템
- tmi.nexon.com: 카트라이더 전적검색
- 

### 5. 웹으로 표현하는 데이터 시각화와 스토리텔링



### 6. 데이터 분석팀과 이스포츠 선수단의 신뢰 쌓기 프로세스
